{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0150892c-fc57-40bf-8faf-c35027a29c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev212/Research/NLP Species-Allergy/venv/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/dev212/Research/NLP Species-Allergy/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdf0f6ec-d1a2-44cd-bdf8-a22752d4b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/user-prompts.csv\")\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "texts = df[\"text\"].to_numpy()\n",
    "species = df[\"species\"].unique()\n",
    "allergies = df[\"allergies\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb911cd-989b-4250-999e-bc568e1fc675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guinea -> NOUN\n",
      "pig -> NOUN\n",
      "spinach -> NOUN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"7a31554ddc8047c481ceeaef29526306-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">My</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">guinea</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">pig</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">can</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">not</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">eat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">spinach.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7a31554ddc8047c481ceeaef29526306-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7a31554ddc8047c481ceeaef29526306-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7a31554ddc8047c481ceeaef29526306-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7a31554ddc8047c481ceeaef29526306-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7a31554ddc8047c481ceeaef29526306-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7a31554ddc8047c481ceeaef29526306-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7a31554ddc8047c481ceeaef29526306-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7a31554ddc8047c481ceeaef29526306-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7a31554ddc8047c481ceeaef29526306-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7a31554ddc8047c481ceeaef29526306-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7a31554ddc8047c481ceeaef29526306-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7a31554ddc8047c481ceeaef29526306-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1090.0,266.5 L1098.0,254.5 1082.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(texts[0])\n",
    "\n",
    "for token in doc:\n",
    "    if token.pos_ == 'NOUN':\n",
    "        print(token.text, '->', token.pos_)\n",
    "\n",
    "spacy.displacy.render(doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40719be7-dee1-4716-ac2c-a9f8f68af3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My guinea pig cannot eat spinach.\n",
      "[('spinach', 'negative')]\n"
     ]
    }
   ],
   "source": [
    "negative_words = [\"hate\", \"dislike\", \"awful\", \"terrible\", \"bad\", \"not\"]\n",
    "positive_words = [\"love\", \"like\", \"enjoy\", \"great\", \"awesome\", \"delicious\"]\n",
    "\n",
    "def is_negated(token):\n",
    "    # Check for negation or sentiment-related negative words\n",
    "    if token.dep_ == \"neg\" or token.lemma_.lower() in negative_words:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Function to check if a word is positive sentiment\n",
    "def is_positive_sentiment(token):\n",
    "    if token.lemma_.lower() in positive_words:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Function to extract food and apply sentiment rules\n",
    "def extract_food_and_sentiment(text, labels, ps):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Initialize PhraseMatcher and add patterns for food items\n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    patterns = [nlp.make_doc(label) for label in labels]\n",
    "    matcher.add(ps, None, *patterns)\n",
    "\n",
    "    detected_foods = []\n",
    "\n",
    "    # Apply the PhraseMatcher to find food phrases\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        food_phrase = doc[start:end]\n",
    "        sentiment = \"neutral\"  # Default assumption is neutral sentiment\n",
    "        \n",
    "        # Check for negation around the food phrase\n",
    "        is_neg = False\n",
    "        # Check if negation is before or after the food phrase\n",
    "        if start > 0 and is_negated(doc[start - 1]):\n",
    "            is_neg = True\n",
    "        if end < len(doc) and is_negated(doc[end]):\n",
    "            is_neg = True\n",
    "        \n",
    "        # Also, check for negation in surrounding words before and after the phrase\n",
    "        context_range = 3  # Look at 3 words before and after the food phrase\n",
    "        if any(is_negated(token) for token in doc[max(0, start-context_range):min(len(doc), end+context_range)]):\n",
    "            is_neg = True\n",
    "        \n",
    "        if is_neg:\n",
    "            sentiment = \"negative\"\n",
    "        \n",
    "        # Check for positive sentiment in the surrounding words\n",
    "        if any(is_positive_sentiment(token) for token in doc[max(0, start-context_range):min(len(doc), end+context_range)]):\n",
    "            sentiment = \"positive\"\n",
    "        \n",
    "        # Add the detected food phrase and its sentiment to the list\n",
    "        detected_foods.append((food_phrase.text.lower(), sentiment))\n",
    "\n",
    "    return detected_foods\n",
    "\n",
    "# Test with an example sentence\n",
    "text = texts[0]\n",
    "print(text)\n",
    "result = extract_food_and_sentiment(text, allergies, \"ALLERGIES\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc7c9a4b-5fac-4f7c-8f36-876a8686b952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My guinea pig cannot eat milk.\n",
      "Species with Allergens and Sentiment (with positions):\n",
      "Species: guinea pig, Allergen: milk, Sentiment: negative, Species position: (3, 10), Allergen position: (25, 25)\n"
     ]
    }
   ],
   "source": [
    "negative_words = [\"hate\", \"dislike\", \"awful\", \"terrible\", \"bad\", \"not\", \"sensitive\", \"allergic\", \"allergies\"]\n",
    "positive_words = [\"love\", \"like\", \"enjoy\", \"great\", \"awesome\", \"delicious\"]\n",
    "\n",
    "def is_negated(token, negative_words):\n",
    "    return token.dep_ == \"neg\" or token.lemma_.lower() in negative_words\n",
    "\n",
    "def is_positive_sentiment(token, positive_words):\n",
    "    return token.lemma_.lower() in positive_words\n",
    "\n",
    "# Main function to extract species first, then allergens, and their sentiment\n",
    "def extract_species_and_allergens(text, allergens, valid_species, category_name=\"ALLERGENS\"):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Initialize the PhraseMatcher for allergens\n",
    "    allergen_matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "    allergen_patterns = [nlp.make_doc(allergen) for allergen in allergens]\n",
    "    allergen_matcher.add(category_name, None, *allergen_patterns)\n",
    "\n",
    "    # Initialize the PhraseMatcher for species (valid species could be multi-word)\n",
    "    species_matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "    species_patterns = [nlp.make_doc(species) for species in valid_species]\n",
    "    species_matcher.add(\"SPECIES\", None, *species_patterns)\n",
    "\n",
    "    detected_species_allergens = []\n",
    "\n",
    "    # Apply the species matcher to detect species\n",
    "    species_matches = species_matcher(doc)\n",
    "\n",
    "    species_positions = []\n",
    "    for match_id, start, end in species_matches:\n",
    "        species_name = doc[start:end].text.lower()\n",
    "        species_positions.append((start, end, species_name, doc[start].idx, doc[end - 1].idx))\n",
    "\n",
    "    allergen_matches = allergen_matcher(doc)\n",
    "\n",
    "    allergen_sentiment_map = {}\n",
    "\n",
    "    for allergen_match_id, allergen_start, allergen_end in allergen_matches:\n",
    "        allergen_phrase = doc[allergen_start:allergen_end].text.lower()\n",
    "        sentiment = \"neutral\"\n",
    "\n",
    "        context_range = 3\n",
    "        context = doc[max(0, allergen_start - context_range):min(len(doc), allergen_end + context_range)]\n",
    "        is_neg = any(is_negated(token, negative_words) for token in context)\n",
    "        is_pos = any(is_positive_sentiment(token, positive_words) for token in context)\n",
    "\n",
    "        if is_neg:\n",
    "            sentiment = \"negative\"\n",
    "        elif is_pos:\n",
    "            sentiment = \"positive\"\n",
    "\n",
    "        allergen_sentiment_map[allergen_phrase] = sentiment\n",
    "\n",
    "    for allergen_phrase, sentiment in allergen_sentiment_map.items():\n",
    "        closest_species = None\n",
    "        allergen_start_pos = None\n",
    "\n",
    "        # Get the allergen start position\n",
    "        for allergen_match_id, allergen_start, allergen_end in allergen_matches:\n",
    "            if allergen_phrase == doc[allergen_start:allergen_end].text.lower():\n",
    "                allergen_start_pos = doc[allergen_start].idx\n",
    "\n",
    "        # Find the closest species before the allergen\n",
    "        for species_start, species_end, species, species_start_idx, species_end_idx in species_positions:\n",
    "            species_end_pos = species_end_idx  # Get the species' end position\n",
    "\n",
    "            if species_end_pos < allergen_start_pos:  # Species appears before allergen\n",
    "                closest_species = (species, species_start_idx, species_end_idx)\n",
    "            else:\n",
    "                break  # No need to check further species\n",
    "\n",
    "        if closest_species:\n",
    "            species_name, species_start_idx, species_end_idx = closest_species\n",
    "            allergen_start = doc[allergen_start].idx\n",
    "            allergen_end = doc[allergen_end - 1].idx\n",
    "            detected_species_allergens.append((species_name, allergen_phrase, sentiment, species_start_idx, species_end_idx, allergen_start, allergen_end))\n",
    "\n",
    "    return detected_species_allergens\n",
    "\n",
    "text = np.random.choice(texts, 1)[0]\n",
    "print(text)\n",
    "allergens = allergies.tolist()\n",
    "valid_species = species.tolist()\n",
    "\n",
    "result = extract_species_and_allergens(text, allergens, valid_species)\n",
    "\n",
    "print(\"Species with Allergens and Sentiment (with positions):\")\n",
    "for item in result:\n",
    "    species_name, allergen, sentiment, species_start_idx, species_end_idx, allergen_start, allergen_end = item\n",
    "    print(f\"Species: {species_name}, Allergen: {allergen}, Sentiment: {sentiment}, \"\n",
    "          f\"Species position: ({species_start_idx}, {species_end_idx}), \"\n",
    "          f\"Allergen position: ({allergen_start}, {allergen_end})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed94abf-6f8d-418c-a986-ddf2980f015b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid_species' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvalid_species\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_species' is not defined"
     ]
    }
   ],
   "source": [
    "valid_species, allergens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
